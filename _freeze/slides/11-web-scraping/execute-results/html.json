{
  "hash": "8bd35135cfa7a222a5ebcefd5d895628",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Web scraping\"\nsubtitle: \"Lecture 11\"\ndate: \"February 22, 2024\"\nformat: \n  revealjs:\n    footer: \"[üîó sta199-s24.github.io](https://sta199-s24.github.io/) &nbsp;¬∑&nbsp; [‚ùì Ask on Ed](https://edstem.org/us/courses/50730)\"\n---\n\n\n\n\n\n\n# Warm up\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## While you wait for class to begin...\n\n::: nonincremental\n-   If you haven't yet done so: Install a Chrome browser and the SelectorGadget extension:\n    -   [Chrome](https://www.google.com/chrome/)\n    -   [SelectorGadget](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en)\n-   Go to your `ae` repo, commit any remaining changes, push, and then pull for today's application exercise.\n:::\n\n## Announcements\n\n-   Lab 4 on Monday\n\n-   Challenge: Resist the urge to ask a GPT before spending some time thinking!\n\n## Reading The Chronicle\n\n::: question\nHow often do you read The Chronicle?\n\n-   Every day\n\n-   3-5 times a week\n\n-   Once a week\n\n-   Rarely\n:::\n\n\n\n\n\n\n```{=html}\n<iframe allowfullscreen frameborder=\"0\" height=\"100%\" mozallowfullscreen style=\"min-width: 500px; min-height: 355px\" src=\"https://app.wooclap.com/STA199S24?from=status-bar?\" width=\"100%\"></iframe>\n```\n\n\n\n\n\n## Reading The Chronicle\n\n::: question\nWhat do you think is the most common word in the titles of The Chronicle opinion pieces?\n:::\n\n\n\n\n\n\n```{=html}\n<iframe allowfullscreen frameborder=\"0\" height=\"100%\" mozallowfullscreen style=\"min-width: 500px; min-height: 355px\" src=\"https://app.wooclap.com/STA199S24?from=status-bar?\" width=\"100%\"></iframe>\n```\n\n\n\n\n\n## Analyzing The Chronicle\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11-web-scraping_files/figure-html/chronicle-common-words-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n## Reading The Chronicle\n\n::: question\nHow do you think the sentiments in opinion pieces in The Chronicle compare across authors?\nRoughly the same?\nWildly different?\nSomewhere in between?\n:::\n\n## Analyzing The Chronicle\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](11-web-scraping_files/figure-html/chronicle-sentiments-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\n\n\n## All of this analysis is done in R! {.centered}\n\n::: hand\n(mostly) with tools you already know!\n:::\n\n## Common words in The Chronicle titles {.smaller}\n\nCode for the earlier plot:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2-3|4|5|6|7-20\"}\nstop_words <- read_csv(\"data/stop-words.csv\")\nchronicle |>\n  tidytext::unnest_tokens(word, title) |>\n  anti_join(stop_words) |>\n  count(word, sort = TRUE) |>\n  slice_head(n = 20) |>\n  mutate(word = fct_reorder(word, n)) |>\n  ggplot(aes(y = word, x = n, fill = log(n))) +\n  geom_col(show.legend = FALSE) +\n  theme_minimal(base_size = 16) +\n  labs(\n    x = \"Number of mentions\",\n    y = \"Word\",\n    title = \"The Chronicle - Opinion pieces\",\n    subtitle = \"Common words in the 500 most recent opinion pieces\",\n    caption = \"Source: Data scraped from The Chronicle on Feb 21, 2024\"\n  ) +\n  theme(\n    plot.title.position = \"plot\",\n    plot.caption = element_text(color = \"gray30\")\n  )\n```\n:::\n\n\n\n\n\n\n## Avg sentiment scores of abstracts {.smaller}\n\nCode for the earlier plot:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2-4|5-19|20|21|22-27|28-33|34-52\"}\nafinn_sentiments <- read_csv(\"data/afinn-sentiments.csv\")\nchronicle |>\n  tidytext::unnest_tokens(word, abstract) |>\n  anti_join(stop_words) |>\n  left_join(afinn_sentiments) |> \n  group_by(author, title) |>\n  summarize(total_sentiment = sum(value, na.rm = TRUE), .groups = \"drop\") |>\n  group_by(author) |>\n  summarize(\n    n_articles = n(),\n    avg_sentiment = mean(total_sentiment, na.rm = TRUE),\n  ) |>\n  filter(n_articles > 1 & !is.na(author)) |>\n  arrange(desc(avg_sentiment)) |>\n  slice(c(1:10, 49:58)) |>\n  mutate(\n    author = fct_reorder(author, avg_sentiment),\n    neg_pos = if_else(avg_sentiment < 0, \"neg\", \"pos\"),\n    label_position = if_else(neg_pos == \"neg\", 0.25, -0.25)\n  ) |>\n  ggplot(aes(y = author, x = avg_sentiment)) +\n  geom_col(aes(fill = neg_pos), show.legend = FALSE) +\n  geom_text(\n    aes(x = label_position, label = author, color = neg_pos),\n    hjust = c(rep(1,10), rep(0, 10)),\n    show.legend = FALSE,\n    fontface = \"bold\"\n  ) +\n  geom_text(\n    aes(label = round(avg_sentiment, 1)),\n    hjust = c(rep(1.25,10), rep(-0.25, 10)),\n    color = \"white\",\n    fontface = \"bold\"\n  ) +\n  scale_fill_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  scale_color_manual(values = c(\"neg\" = \"#4d4009\", \"pos\" = \"#FF4B91\")) +\n  scale_x_continuous(breaks = -5:5, minor_breaks = NULL) +\n  scale_y_discrete(breaks = NULL) +\n  coord_cartesian(xlim = c(-5, 5)) +\n  labs(\n    x = \"negative  ‚Üê     Average sentiment score (AFINN)     ‚Üí  positive\",\n    y = NULL,\n    title = \"The Chronicle - Opinion pieces\\nAverage sentiment scores of abstracts by author\",\n    subtitle = \"Top 10 average positive and negative scores\",\n    caption = \"Source: Data scraped from The Chronicle on Feb 21, 2024\"\n  ) +\n  theme_void(base_size = 16) +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5, margin = unit(c(0.5, 0, 1, 0), \"lines\")),\n    axis.text.y = element_blank(),\n    plot.caption = element_text(color = \"gray30\")\n  )\n```\n:::\n\n\n\n\n\n\n## Where is the data coming from? {.smaller}\n\n::: center\n<https://www.dukechronicle.com/section/opinion>\n:::\n\n[![](images/chronicle-opinion-page.png){fig-align=\"center\" width=\"800\"}](https://www.dukechronicle.com/section/opinion?page=1&per_page=500)\n\n## Where is the data coming from? {.smaller}\n\n::: columns\n::: {.column width=\"20%\"}\n[![](images/chronicle-opinion-page.png){fig-align=\"center\" width=\"800\"}](https://www.dukechronicle.com/section/opinion?page=1&per_page=500)\n:::\n\n::: {.column width=\"80%\"}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchronicle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 √ó 6\n   title                                           author date       abstract column url  \n   <chr>                                           <chr>  <date>     <chr>    <chr>  <chr>\n 1 All the world‚Äôs a stage                         Anna ‚Ä¶ 2024-02-22 If we a‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 2 Words that matter: For Alexei Navalny           Carol‚Ä¶ 2024-02-22 In some‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 3 Which would you save: Friend or romantic partn‚Ä¶ Jess ‚Ä¶ 2024-02-22 Love sh‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 4 Happiness is not what you‚Äôre looking for        Paul ‚Ä¶ 2024-02-21 We hing‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 5 Closing Duke's Herbarium: A fear of long-term ‚Ä¶ Matth‚Ä¶ 2024-02-21 Without‚Ä¶ LETTE‚Ä¶ http‚Ä¶\n 6 CS Majors launch 'ambiguous and labelless rela‚Ä¶ Monda‚Ä¶ 2024-02-20 Unlike ‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 7 The fear of being single                        Heidi‚Ä¶ 2024-02-20 But it ‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n 8 Save the Duke Herbarium                         Henry‚Ä¶ 2024-02-17 The Duk‚Ä¶ LETTE‚Ä¶ http‚Ä¶\n 9 What Duke can learn from retiring ex-president‚Ä¶ Rober‚Ä¶ 2024-02-17 In Duke‚Ä¶ GUEST‚Ä¶ http‚Ä¶\n10 Love, love                                      Gabri‚Ä¶ 2024-02-16 Somehow‚Ä¶ STUDE‚Ä¶ http‚Ä¶\n# ‚Ñπ 490 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n:::\n:::\n\n# Web scraping\n\n## Scraping the web: what? why? {.smaller}\n\n-   Increasing amount of data is available on the web\n\n-   These data are provided in an unstructured format: you can always copy&paste, but it's time-consuming and prone to errors\n\n-   Web scraping is the process of extracting this information automatically and transform it into a structured dataset\n\n-   Two different scenarios:\n\n    -   Screen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy).\n\n    -   Web APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files.\n\n## Hypertext Markup Language {.smaller}\n\nMost of the data on the web is still largely available as HTML - while it is structured (hierarchical) it often is not available in a form useful for analysis (flat / tidy).\n\n::: small\n``` html\n<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <p align=\"center\">Hello world!</p>\n    <br/>\n    <div class=\"name\" id=\"first\">John</div>\n    <div class=\"name\" id=\"last\">Doe</div>\n    <div class=\"contact\">\n      <div class=\"home\">555-555-1234</div>\n      <div class=\"home\">555-555-2345</div>\n      <div class=\"work\">555-555-9999</div>\n      <div class=\"fax\">555-555-8888</div>\n    </div>\n  </body>\n</html>\n```\n:::\n\n## rvest {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n-   The **rvest** package makes basic processing and manipulation of HTML data straight forward\n-   It's designed to work with pipelines built with `|>`\n-   [rvest.tidyverse.org](https://rvest.tidyverse.org)\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\n```\n:::\n\n\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n[![](images/rvest.png){fig-alt=\"rvest hex logo\" fig-align=\"right\" width=\"400\"}](https://rvest.tidyverse.org/)\n:::\n:::\n\n## rvest {.smaller}\n\nCore functions:\n\n-   `read_html()` - read HTML data from a url or character string.\n\n-   `html_elements()` - select specified elements from the HTML document using CSS selectors (or xpath).\n\n-   `html_element()` - select a single element from the HTML document using CSS selectors (or xpath).\n\n-   `html_table()` - parse an HTML table into a data frame.\n\n-   `html_text()` / `html_text2()` - extract tag's text content.\n\n-   `html_name` - extract a tag/element's name(s).\n\n-   `html_attrs` - extract all attributes.\n\n-   `html_attr` - extract attribute value(s) by name.\n\n## html, rvest, & xml2 {.smaller}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhtml <- \n'<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <p align=\"center\">Hello world!</p>\n    <br/>\n    <div class=\"name\" id=\"first\">John</div>\n    <div class=\"name\" id=\"last\">Doe</div>\n    <div class=\"contact\">\n      <div class=\"home\">555-555-1234</div>\n      <div class=\"home\">555-555-2345</div>\n      <div class=\"work\">555-555-9999</div>\n      <div class=\"fax\">555-555-8888</div>\n    </div>\n  </body>\n</html>'\n```\n:::\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{html_document}\n<html>\n[1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\\n<title ...\n[2] <body>\\n    <p align=\"center\">Hello world!</p>\\n    <br><div class=\"name\" id=\"first ...\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Selecting elements\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (1)}\n[1] <p align=\"center\">Hello world!</p>\n```\n\n\n:::\n:::\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\") |> html_text()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello world!\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\") |> html_name()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"p\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\") |> html_attrs()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n   align \n\"center\" \n```\n\n\n:::\n:::\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"p\") |> html_attr(\"align\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"center\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## More selecting tags {.smaller}\n\n::: medium\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"div\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (7)}\n[1] <div class=\"name\" id=\"first\">John</div>\n[2] <div class=\"name\" id=\"last\">Doe</div>\n[3] <div class=\"contact\">\\n      <div class=\"home\">555-555-1234</div>\\n      <div class ...\n[4] <div class=\"home\">555-555-1234</div>\n[5] <div class=\"home\">555-555-2345</div>\n[6] <div class=\"work\">555-555-9999</div>\n[7] <div class=\"fax\">555-555-8888</div>\n```\n\n\n:::\n:::\n\n\n\n\n\n:::\n\n. . .\n\n::: medium\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"div\") |> html_text()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"John\"                                                                                  \n[2] \"Doe\"                                                                                   \n[3] \"\\n      555-555-1234\\n      555-555-2345\\n      555-555-9999\\n      555-555-8888\\n    \"\n[4] \"555-555-1234\"                                                                          \n[5] \"555-555-2345\"                                                                          \n[6] \"555-555-9999\"                                                                          \n[7] \"555-555-8888\"                                                                          \n```\n\n\n:::\n:::\n\n\n\n\n\n:::\n\n## CSS selectors {.smaller}\n\n-   We will use a tool called SelectorGadget to help us identify the HTML elements of interest by constructing a CSS selector which can be used to subset the HTML document.\n\n. . .\n\n-   Some examples of basic selector syntax is below,\n\n::: small\n| Selector            | Example         | Description                                        |\n|:----------------|:----------------|:--------------------------------------|\n| .class              | `.title`        | Select all elements with class=\"title\"             |\n| #id                 | `#name`         | Select all elements with id=\"name\"                 |\n| element             | `p`             | Select all \\<p\\> elements                          |\n| element element     | `div p`         | Select all \\<p\\> elements inside a \\<div\\> element |\n| element\\>element    | `div > p`       | Select all \\<p\\> elements with \\<div\\> as a parent |\n| \\[attribute\\]       | `[class]`       | Select all elements with a class attribute         |\n| \\[attribute=value\\] | `[class=title]` | Select all elements with class=\"title\"             |\n:::\n\n## CSS classes and ids\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\".name\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (2)}\n[1] <div class=\"name\" id=\"first\">John</div>\n[2] <div class=\"name\" id=\"last\">Doe</div>\n```\n\n\n:::\n:::\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"div.name\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (2)}\n[1] <div class=\"name\" id=\"first\">John</div>\n[2] <div class=\"name\" id=\"last\">Doe</div>\n```\n\n\n:::\n:::\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html) |> html_elements(\"#first\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_nodeset (1)}\n[1] <div class=\"name\" id=\"first\">John</div>\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## Text with `html_text()` vs. `html_text2()`\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhtml = read_html(\n  \"<p>  \n    This is the first sentence in the paragraph.\n    This is the second sentence that should be on the same line as the first sentence.<br>This third sentence should start on a new line.\n  </p>\"\n)\n```\n:::\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhtml |> html_text()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"  \\n    This is the first sentence in the paragraph.\\n    This is the second sentence that should be on the same line as the first sentence.This third sentence should start on a new line.\\n  \"\n```\n\n\n:::\n\n```{.r .cell-code}\nhtml |> html_text2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"This is the first sentence in the paragraph. This is the second sentence that should be on the same line as the first sentence.\\nThis third sentence should start on a new line.\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## HTML tables with `html_table()` {.smaller}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhtml_table = \n'<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <table>\n      <tr> <th>a</th> <th>b</th> <th>c</th> </tr>\n      <tr> <td>1</td> <td>2</td> <td>3</td> </tr>\n      <tr> <td>2</td> <td>3</td> <td>4</td> </tr>\n      <tr> <td>3</td> <td>4</td> <td>5</td> </tr>\n    </table>\n  </body>\n</html>'\n```\n:::\n\n\n\n\n\n\n. . .\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_html(html_table) |>\n  html_elements(\"table\") |> \n  html_table()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n# A tibble: 3 √ó 3\n      a     b     c\n  <int> <int> <int>\n1     1     2     3\n2     2     3     4\n3     3     4     5\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## SelectorGadget\n\n**SelectorGadget** ([selectorgadget.com](http://selectorgadget.com)) is a javascript based tool that helps you interactively build an appropriate CSS selector for the content you are interested in.\n\n![](images/selectorgadget.png){fig-align=\"center\" width=\"1000\"}\n\n# Application exercise\n\n## Opinion articles in The Chronicle\n\nGo to <https://www.dukechronicle.com/section/opinion?page=1&per_page=500>.\n\n::: question\nHow many articles are on the page?\n:::\n\n## Goal\n\n::: columns\n::: {.column width=\"50%\"}\n-   Scrape data and organize it in a tidy format in R\n-   Perform light text parsing to clean data\n-   Summarize and visualze the data\n:::\n\n::: {.column width=\"50%\"}\n![](images/chronicle-data.png){fig-align=\"center\"}\n:::\n:::\n\n## `ae-09`\n\n::: appex\n-   Go to the project navigator in RStudio (top right corner of your RStudio window) and open the project called ae.\n-   If there are any uncommitted files, commit them, and then click Pull.\n-   Open the file called `chronicle-scrape.R` and follow along.\n:::\n\n## Recap\n\n-   Use the SelectorGadget identify tags for elements you want to grab\n-   Use rvest to first read the whole page (into R) and then parse the object you've read in to the elements you're interested in\n-   Put the components together in a data frame (a tibble) and analyze it like you analyze any other data\n\n## A new R workflow {.smaller}\n\n-   When working in a Quarto document, your analysis is re-run each time you knit\n\n-   If web scraping in a Quarto document, you'd be re-scraping the data each time you knit, which is undesirable (and not *nice*)!\n\n-   An alternative workflow:\n\n    -   Use an R script to save your code\n    -   Saving interim data scraped using the code in the script as CSV or RDS files\n    -   Use the saved data in your analysis in your Quarto document\n\n# Web scraping considerations\n\n## Ethics: \"Can you?\" vs \"Should you?\"\n\n![](images/ok-cupid-1.png){fig-align=\"center\" width=\"800\"}\n\n::: aside\nSource: Brian Resnick, [Researchers just released profile data on 70,000 OkCupid users without permission](https://www.vox.com/2016/5/12/11666116/70000-okcupid-users-data-release), Vox.\n:::\n\n## \"Can you?\" vs \"Should you?\"\n\n![](images/ok-cupid-2.png){fig-align=\"center\" width=\"699\"}\n\n## Challenges: Unreliable formatting\n\n![](images/unreliable-formatting.png){fig-align=\"center\" width=\"699\"}\n\n::: aside\n[alumni.duke.edu/news/notable-alumni](https://alumni.duke.edu/news/notable-alumni)\n:::\n\n## Challenges: Data broken into many pages\n\n![](images/many-pages.png){fig-align=\"center\"}\n\n## Workflow: Screen scraping vs. APIs\n\nTwo different scenarios for web scraping:\n\n-   Screen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\n\n-   Web APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files\n",
    "supporting": [
      "11-web-scraping_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}